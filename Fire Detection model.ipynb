{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf63363b",
   "metadata": {},
   "source": [
    "# IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad7fb597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47d76cc",
   "metadata": {},
   "source": [
    "# LOADING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96975072",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [\n",
    "    r\"E:\\aditya\\fire_dataset\\fire_images\",\n",
    "    r\"E:\\aditya\\fire_dataset\\non_fire_images\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc9bf1a",
   "metadata": {},
   "source": [
    "# Import Libraries:\n",
    "\n",
    "The code imports NumPy as np and OpenCV (cv2) for image processing.\n",
    "Define Function load_images(folder):\n",
    "\n",
    "Creates empty lists images and labels to store images and their corresponding labels.\n",
    "Iterates through each subfolder in the training data folder.\n",
    "Initializes a label variable to assign numerical labels to each class.\n",
    "Iterates through each image file in the subfolders.\n",
    "Load and Preprocess Images:\n",
    "\n",
    "Uses OpenCV's imread() function to read each image file as grayscale.\n",
    "Resizes the grayscale image to 48x48 pixels using OpenCV's resize() function.\n",
    "Handle Errors Gracefully:\n",
    "\n",
    "Utilizes a try-except block to handle any errors encountered during image loading.\n",
    "Store Images and Labels:\n",
    "\n",
    "Appends the resized grayscale image to the images list.\n",
    "Appends the corresponding numerical label to the labels list.\n",
    "Return Arrays:\n",
    "\n",
    "Converts images and labels lists to NumPy arrays.\n",
    "Returns the arrays containing the images and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90d67357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(training_data):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i in range(len(training_data)):\n",
    "        folder = training_data[i]\n",
    "        label = i\n",
    "        for filename in os.listdir(folder):\n",
    "            try:\n",
    "                img = cv2.imread(os.path.join(folder,filename),cv2.IMREAD_GRAYSCALE)\n",
    "                img = cv2.resize(img, (48,48))\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {os.path.join(folder, filename)}: {e}\")\n",
    "    return np.array(images), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14136af7",
   "metadata": {},
   "source": [
    "# Import Libraries:\n",
    "\n",
    "The code imports necessary libraries for loading, splitting, and preprocessing the data.\n",
    "Define Function load_images(training_data_path):\n",
    "\n",
    "Creates empty lists to store images and labels.\n",
    "Gets a list of all files in the training data directory using os.listdir().\n",
    "Loops through each file name in the list.\n",
    "Load Images and Labels:\n",
    "\n",
    "Reads each image file using cv2.imread() and converts it into an array of pixels.\n",
    "Appends these pixel arrays (images) into the images list.\n",
    "Extracts digits from each file name using regex pattern matching and appends them into the labels list.\n",
    "Return Data:\n",
    "\n",
    "Returns both lists (images and labels) as the output of the function.\n",
    "Load and Split Data:\n",
    "\n",
    "Calls the load_images() function with the path to the training dataset.\n",
    "Assigns the output (lists of images and labels) to variables X_train and y_train.\n",
    "Split Data into Train and Test Sets:\n",
    "\n",
    "Uses train_test_split() method from the sklearn library to split the data into random train and test subsets.\n",
    "Passes four arguments:\n",
    "i) X_train: Features/inputs data,\n",
    "ii) y_train: Target/output values,\n",
    "iii) test_size: Specifies the proportion of the original data kept aside for testing,\n",
    "iv) random_state: Controls shuffling applied on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "36029107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image E:\\aditya\\fire_dataset\\non_fire_images\\non_fire.189.png: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "images, labels = load_images(training_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(images,labels, test_size=0.2, random_state=42)\n",
    "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1).astype('float32')/255\n",
    "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1).astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a9305b",
   "metadata": {},
   "source": [
    "# The code\n",
    "converts the training and testing labels into categorical data.\n",
    " The input code is too short to provide a detailed and accurate answer. \n",
    "To gain deeper insight, try again using a longer piece of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db5f6c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7b1714",
   "metadata": {},
   "source": [
    "# Import Libraries:\n",
    "\n",
    "The code imports the necessary libraries, including Keras and TensorFlow, for building a convolutional neural network (CNN) model.\n",
    "Define Model:\n",
    "\n",
    "It defines the model using the Sequential() function from Keras, allowing the creation of a sequential stack of layers for the CNN.\n",
    "Convolutional Layers:\n",
    "\n",
    "The first layer is a Conv2D layer with 32 filters (feature detectors) of size 3x3 pixels.\n",
    "It uses the 'relu' activation function to introduce non-linearity.\n",
    "The input shape is specified as 48x48 pixels with one color channel (grayscale), represented as a matrix of numbers with dimensions 48x48x1.\n",
    "The second Conv2D layer has 64 filters, also with 'relu' activation function and a kernel size of 3x3 pixels.\n",
    "Pooling Layer:\n",
    "\n",
    "A MaxPooling2D layer follows with a pool size of (2,2), reducing the spatial size of the representation while retaining important features from previous layers.\n",
    "Dropout Regularization:\n",
    "\n",
    "To prevent overfitting, a Dropout layer is added after pooling with a dropout rate of 0.25.\n",
    "This means that randomly selected neurons will be ignored during training to improve generalization ability.\n",
    "Flattening:\n",
    "\n",
    "The pooled feature maps are flattened into one long vector to be fed into fully connected Dense layers later on.\n",
    "Dense Layers:\n",
    "\n",
    "Two Dense layers are added:\n",
    "The first one has an output dimensionality of 128 units.\n",
    "The second Dense layer outputs final prediction probabilities for given class labels using the softmax activation function.\n",
    "The model outputs predictions for the \"happy\" class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "98d14d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477667ae",
   "metadata": {},
   "source": [
    "# Import Libraries:\n",
    "\n",
    "Necessary libraries, including Keras and TensorFlow, are imported.\n",
    "Load and Split Dataset:\n",
    "\n",
    "The dataset is loaded using Keras's load_data() function, which automatically splits it into training and testing sets.\n",
    "80% of the data is used for training, and 20% for testing.\n",
    "Preprocess Data:\n",
    "\n",
    "Data is reshaped into a format suitable for CNN input.\n",
    "Each image is converted from an array of pixels to a matrix of pixel values.\n",
    "Pixel values are normalized between 0 and 1.\n",
    "Define CNN Model:\n",
    "\n",
    "CNN model is defined using Sequential().\n",
    "Three convolutional layers followed by max pooling layers extract features from images.\n",
    "Features are flattened and passed through two fully connected dense layers.\n",
    "The output layer has two nodes representing \"fire\" or \"no fire\".\n",
    "Compile Model:\n",
    "\n",
    "Model is compiled using categorical crossentropy as the loss function since there are more than two classes.\n",
    "Adam optimizer is specified.\n",
    "Accuracy is chosen as the metric for evaluation during training.\n",
    "Train Model:\n",
    "\n",
    "fit() method is used for training, taking parameters like batch size, epochs, verbosity, and validation data.\n",
    "The model is trained on the training data.\n",
    "Save Model:\n",
    "\n",
    "After training, the model is saved as a .h5 file for future use.\n",
    "This allows for reuse or deployment without retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "169a75c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - accuracy: 0.8685 - loss: 0.3566 - val_accuracy: 0.8450 - val_loss: 0.4070\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.8902 - loss: 0.2655 - val_accuracy: 0.8600 - val_loss: 0.3760\n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.8922 - loss: 0.2440 - val_accuracy: 0.8650 - val_loss: 0.3882\n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.9024 - loss: 0.2243 - val_accuracy: 0.8800 - val_loss: 0.3985\n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.9182 - loss: 0.1765 - val_accuracy: 0.8800 - val_loss: 0.3646\n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.9306 - loss: 0.1741 - val_accuracy: 0.8600 - val_loss: 0.3656\n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.9202 - loss: 0.1904 - val_accuracy: 0.8550 - val_loss: 0.4006\n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.9285 - loss: 0.1683 - val_accuracy: 0.8850 - val_loss: 0.3926\n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.9364 - loss: 0.1530 - val_accuracy: 0.8950 - val_loss: 0.4251\n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.9411 - loss: 0.1377 - val_accuracy: 0.8800 - val_loss: 0.3913\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics =['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=10, verbose=1, validation_data=(X_test,y_test))\n",
    "model.save(\"fire_detection_model.keras\")  # Use either .keras or .h5 extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2637d183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
